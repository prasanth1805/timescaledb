-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
-- test add and remove refresh policy apis
SET ROLE :ROLE_DEFAULT_PERM_USER;
--TEST1 ---
--basic test with count
CREATE TABLE int_tab (a integer, b integer, c integer);
SELECT table_name FROM create_hypertable('int_tab', 'a', chunk_time_interval=> 10);
NOTICE:  adding not-null constraint to column "a"
 table_name 
------------
 int_tab
(1 row)

INSERT INTO int_tab VALUES( 3 , 16 , 20);
INSERT INTO int_tab VALUES( 1 , 10 , 20);
INSERT INTO int_tab VALUES( 1 , 11 , 20);
INSERT INTO int_tab VALUES( 1 , 12 , 20);
INSERT INTO int_tab VALUES( 1 , 13 , 20);
INSERT INTO int_tab VALUES( 1 , 14 , 20);
INSERT INTO int_tab VALUES( 2 , 14 , 20);
INSERT INTO int_tab VALUES( 2 , 15 , 20);
INSERT INTO int_tab VALUES( 2 , 16 , 20);
CREATE OR REPLACE FUNCTION integer_now_int_tab() returns int LANGUAGE SQL STABLE as $$ SELECT coalesce(max(a), 0) FROM int_tab $$;
SELECT set_integer_now_func('int_tab', 'integer_now_int_tab');
 set_integer_now_func 
----------------------
 
(1 row)

CREATE MATERIALIZED VIEW mat_m1( a, countb )
WITH (timescaledb.continuous, timescaledb.materialized_only=true)
as
SELECT a, count(b)
FROM int_tab
GROUP BY time_bucket(1, a), a WITH NO DATA;
\c :TEST_DBNAME :ROLE_SUPERUSER
DELETE FROM _timescaledb_config.bgw_job WHERE TRUE;
SET ROLE :ROLE_DEFAULT_PERM_USER;
SELECT count(*) FROM _timescaledb_config.bgw_job;
 count 
-------
     0
(1 row)

\set ON_ERROR_STOP 0
\set VERBOSITY default
SELECT add_continuous_aggregate_policy('int_tab', '1 day'::interval, 10 , '1 h'::interval);
ERROR:  "int_tab" is not a continuous aggregate
SELECT add_continuous_aggregate_policy('mat_m1', '1 day'::interval, 10 , '1 h'::interval);
ERROR:  invalid parameter value for start_offset
HINT:  Use time interval of type integer with the continuous aggregate.
SELECT add_continuous_aggregate_policy('mat_m1', '1 day'::interval, 10 );
ERROR:  function add_continuous_aggregate_policy(unknown, interval, integer) does not exist
LINE 1: SELECT add_continuous_aggregate_policy('mat_m1', '1 day'::in...
               ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
SELECT add_continuous_aggregate_policy('mat_m1', 10, '1 day'::interval, '1 h'::interval);
ERROR:  invalid parameter value for end_offset
HINT:  Use time interval of type integer with the continuous aggregate.
--start_interval < end_interval
SELECT add_continuous_aggregate_policy('mat_m1', 5, 10, '1h'::interval);
ERROR:  policy refresh window too small
DETAIL:  The start and end offsets must cover at least two buckets in the valid time range of type "integer".
--refresh window less than two buckets
SELECT add_continuous_aggregate_policy('mat_m1', 11, 10, '1h'::interval);
ERROR:  policy refresh window too small
DETAIL:  The start and end offsets must cover at least two buckets in the valid time range of type "integer".
SELECT add_continuous_aggregate_policy('mat_m1', 20, 10, '1h'::interval) as job_id \gset
--adding again should warn/error
SELECT add_continuous_aggregate_policy('mat_m1', 20, 10, '1h'::interval, if_not_exists=>false);
ERROR:  continuous aggregate policy already exists for "mat_m1"
DETAIL:  Only one continuous aggregate policy can be created per continuous aggregate and a policy with job id 1000 already exists for "mat_m1".
SELECT add_continuous_aggregate_policy('mat_m1', 20, 15, '1h'::interval, if_not_exists=>true);
WARNING:  continuous aggregate policy already exists for "mat_m1"
DETAIL:  A policy already exists with different arguments.
HINT:  Remove the existing policy before adding a new one.
 add_continuous_aggregate_policy 
---------------------------------
                              -1
(1 row)

SELECT add_continuous_aggregate_policy('mat_m1', 20, 10, '1h'::interval, if_not_exists=>true);
NOTICE:  continuous aggregate policy already exists for "mat_m1", skipping
 add_continuous_aggregate_policy 
---------------------------------
                              -1
(1 row)

-- modify config and try to add, should error out
SELECT config FROM _timescaledb_config.bgw_job where id = :job_id;
                             config                             
----------------------------------------------------------------
 {"end_offset": 10, "start_offset": 20, "mat_hypertable_id": 2}
(1 row)

SELECT hypertable_id as mat_id FROM _timescaledb_config.bgw_job where id = :job_id \gset
\set VERBOSITY terse
\set ON_ERROR_STOP 1
\c :TEST_DBNAME :ROLE_SUPERUSER
UPDATE _timescaledb_config.bgw_job
SET config = jsonb_build_object('mat_hypertable_id', :mat_id)
WHERE id = :job_id;
SET ROLE :ROLE_DEFAULT_PERM_USER;
SELECT config FROM _timescaledb_config.bgw_job where id = :job_id;
          config          
--------------------------
 {"mat_hypertable_id": 2}
(1 row)

\set ON_ERROR_STOP 0
\set VERBOSITY default
SELECT add_continuous_aggregate_policy('mat_m1', 20, 10, '1h'::interval, if_not_exists=>true);
ERROR:  could not find start_offset in config for existing job
SELECT remove_continuous_aggregate_policy('int_tab');
ERROR:  "int_tab" is not a continuous aggregate
SELECT remove_continuous_aggregate_policy('mat_m1');
 remove_continuous_aggregate_policy 
------------------------------------
 
(1 row)

--this one will fail
SELECT remove_continuous_aggregate_policy('mat_m1');
ERROR:  continuous aggregate policy not found for "mat_m1"
SELECT remove_continuous_aggregate_policy('mat_m1', if_not_exists=>true);
NOTICE:  continuous aggregate policy not found for "mat_m1", skipping
 remove_continuous_aggregate_policy 
------------------------------------
 
(1 row)

--now try to add a policy as a different user than the one that created the cagg
--should fail
SET ROLE :ROLE_DEFAULT_PERM_USER_2;
SELECT add_continuous_aggregate_policy('mat_m1', 20, 10, '1h'::interval) as job_id ;
ERROR:  must be owner of continuous aggregate "mat_m1"
\set VERBOSITY terse
\set ON_ERROR_STOP 1
SET ROLE :ROLE_DEFAULT_PERM_USER;
DROP MATERIALIZED VIEW mat_m1;
--- code coverage tests : add policy for timestamp and date based table ---
CREATE TABLE continuous_agg_max_mat_date(time DATE);
SELECT create_hypertable('continuous_agg_max_mat_date', 'time');
NOTICE:  adding not-null constraint to column "time"
            create_hypertable             
------------------------------------------
 (3,public,continuous_agg_max_mat_date,t)
(1 row)

CREATE MATERIALIZED VIEW max_mat_view_date
	WITH (timescaledb.continuous, timescaledb.materialized_only=true)
	AS SELECT time_bucket('7 days', time)
		FROM continuous_agg_max_mat_date
		GROUP BY 1 WITH NO DATA;
\set ON_ERROR_STOP 0
\set VERBOSITY default
SELECT add_continuous_aggregate_policy('max_mat_view_date', '2 days', 10, '1 day'::interval);
ERROR:  invalid parameter value for end_offset
HINT:  Use time interval with a continuous aggregate using timestamp-based time bucket.
--start_interval < end_interval
SELECT add_continuous_aggregate_policy('max_mat_view_date', '1 day'::interval, '2 days'::interval , '1 day'::interval) ;
ERROR:  policy refresh window too small
DETAIL:  The start and end offsets must cover at least two buckets in the valid time range of type "date".
--interval less than two buckets
SELECT add_continuous_aggregate_policy('max_mat_view_date', '7 days', '1 day', '1 day'::interval);
ERROR:  policy refresh window too small
DETAIL:  The start and end offsets must cover at least two buckets in the valid time range of type "date".
SELECT add_continuous_aggregate_policy('max_mat_view_date', '14 days', '1 day', '1 day'::interval);
ERROR:  policy refresh window too small
DETAIL:  The start and end offsets must cover at least two buckets in the valid time range of type "date".
SELECT add_continuous_aggregate_policy('max_mat_view_date', '13 days', '-10 hours', '1 day'::interval);
ERROR:  policy refresh window too small
DETAIL:  The start and end offsets must cover at least two buckets in the valid time range of type "date".
\set VERBOSITY terse
\set ON_ERROR_STOP 1
-- Negative start offset gives two bucket window:
SELECT add_continuous_aggregate_policy('max_mat_view_date', '13 days', '-1 day', '1 day'::interval);
 add_continuous_aggregate_policy 
---------------------------------
                            1001
(1 row)

SELECT remove_continuous_aggregate_policy('max_mat_view_date');
 remove_continuous_aggregate_policy 
------------------------------------
 
(1 row)

-- Both offsets NULL:
SELECT add_continuous_aggregate_policy('max_mat_view_date', NULL, NULL, '1 day'::interval);
 add_continuous_aggregate_policy 
---------------------------------
                            1002
(1 row)

SELECT remove_continuous_aggregate_policy('max_mat_view_date');
 remove_continuous_aggregate_policy 
------------------------------------
 
(1 row)

SELECT add_continuous_aggregate_policy('max_mat_view_date', '15 days', '1 day', '1 day'::interval) as job_id \gset
SELECT config FROM _timescaledb_config.bgw_job
WHERE id = :job_id;
                                     config                                     
--------------------------------------------------------------------------------
 {"end_offset": "@ 1 day", "start_offset": "@ 15 days", "mat_hypertable_id": 4}
(1 row)

INSERT INTO continuous_agg_max_mat_date
	SELECT generate_series('2019-09-01'::date, '2019-09-10'::date, '1 day');
--- to prevent NOTICES set message level to warning
SET client_min_messages TO warning;
CALL run_job(:job_id);
RESET client_min_messages;
DROP MATERIALIZED VIEW max_mat_view_date;
CREATE TABLE continuous_agg_timestamp(time TIMESTAMP);
SELECT create_hypertable('continuous_agg_timestamp', 'time');
NOTICE:  adding not-null constraint to column "time"
           create_hypertable           
---------------------------------------
 (5,public,continuous_agg_timestamp,t)
(1 row)

CREATE MATERIALIZED VIEW max_mat_view_timestamp
	WITH (timescaledb.continuous, timescaledb.materialized_only=true)
	AS SELECT time_bucket('7 days', time)
		FROM continuous_agg_timestamp
		GROUP BY 1 WITH NO DATA;
--the start offset overflows the smallest time value, but is capped at
--the min value
SELECT add_continuous_aggregate_policy('max_mat_view_timestamp', '1000000 years', '1 day' , '1 h'::interval);
 add_continuous_aggregate_policy 
---------------------------------
                            1004
(1 row)

SELECT remove_continuous_aggregate_policy('max_mat_view_timestamp');
 remove_continuous_aggregate_policy 
------------------------------------
 
(1 row)

\set ON_ERROR_STOP 0
\set VERBOSITY default
--start and end offset capped at the lowest time value, which means
--zero size window
SELECT add_continuous_aggregate_policy('max_mat_view_timestamp', '1000000 years', '900000 years' , '1 h'::interval);
ERROR:  policy refresh window too small
DETAIL:  The start and end offsets must cover at least two buckets in the valid time range of type "timestamp without time zone".
SELECT add_continuous_aggregate_policy('max_mat_view_timestamp', '301 days', '10 months' , '1 h'::interval);
ERROR:  policy refresh window too small
DETAIL:  The start and end offsets must cover at least two buckets in the valid time range of type "timestamp without time zone".
\set VERBOSITY terse
\set ON_ERROR_STOP 1
SELECT add_continuous_aggregate_policy('max_mat_view_timestamp', '15 days', '1 h'::interval , '1 h'::interval) as job_id \gset
--- to prevent NOTICES set message level to warning
SET client_min_messages TO warning;
CALL run_job(:job_id);
RESET client_min_messages ;
SELECT config FROM _timescaledb_config.bgw_job
WHERE id = :job_id;
                                     config                                      
---------------------------------------------------------------------------------
 {"end_offset": "@ 1 hour", "start_offset": "@ 15 days", "mat_hypertable_id": 6}
(1 row)

\c :TEST_DBNAME :ROLE_SUPERUSER
UPDATE _timescaledb_config.bgw_job
SET config = jsonb_build_object('mat_hypertable_id', :mat_id)
WHERE id = :job_id;
SET ROLE :ROLE_DEFAULT_PERM_USER;
SELECT config FROM _timescaledb_config.bgw_job where id = :job_id;
          config          
--------------------------
 {"mat_hypertable_id": 2}
(1 row)

\set ON_ERROR_STOP 0
SELECT add_continuous_aggregate_policy('max_mat_view_timestamp', '15 day', '1 day', '1h'::interval, if_not_exists=>true);
ERROR:  could not find start_offset in config for job
SELECT add_continuous_aggregate_policy('max_mat_view_timestamp', 'xyz', '1 day', '1h'::interval, if_not_exists=>true);
ERROR:  invalid input syntax for type interval: "xyz"
\set ON_ERROR_STOP 1
DROP MATERIALIZED VIEW max_mat_view_timestamp;
--smallint table
CREATE TABLE smallint_tab (a smallint);
SELECT table_name FROM create_hypertable('smallint_tab', 'a', chunk_time_interval=> 10);
NOTICE:  adding not-null constraint to column "a"
  table_name  
--------------
 smallint_tab
(1 row)

CREATE OR REPLACE FUNCTION integer_now_smallint_tab() returns smallint LANGUAGE SQL STABLE as $$ SELECT coalesce(max(a)::smallint, 0::smallint) FROM smallint_tab ; $$;
SELECT set_integer_now_func('smallint_tab', 'integer_now_smallint_tab');
 set_integer_now_func 
----------------------
 
(1 row)

CREATE MATERIALIZED VIEW mat_smallint( a, countb )
WITH (timescaledb.continuous, timescaledb.materialized_only=true)
as
SELECT time_bucket( SMALLINT '1', a) , count(*)
FROM smallint_tab
GROUP BY 1 WITH NO DATA;
\set ON_ERROR_STOP 0
\set VERBOSITY default
SELECT add_continuous_aggregate_policy('mat_smallint', 15, 0 , '1 h'::interval);
ERROR:  invalid parameter value for start_offset
HINT:  Use time interval of type smallint with the continuous aggregate.
SELECT add_continuous_aggregate_policy('mat_smallint', 98898::smallint , 0::smallint, '1 h'::interval);
ERROR:  smallint out of range
SELECT add_continuous_aggregate_policy('mat_smallint', 5::smallint, 10::smallint , '1 h'::interval) as job_id \gset
ERROR:  policy refresh window too small
DETAIL:  The start and end offsets must cover at least two buckets in the valid time range of type "smallint".
\set VERBOSITY terse
\set ON_ERROR_STOP 1
SELECT add_continuous_aggregate_policy('mat_smallint', 15::smallint, 0::smallint , '1 h'::interval) as job_id \gset
INSERT INTO smallint_tab VALUES(5);
INSERT INTO smallint_tab VALUES(10);
INSERT INTO smallint_tab VALUES(20);
CALL run_job(:job_id);
SELECT * FROM mat_smallint ORDER BY 1;
 a  | countb 
----+--------
  5 |      1
 10 |      1
(2 rows)

--remove all the data--
TRUNCATE table smallint_tab;
CALL refresh_continuous_aggregate('mat_smallint', NULL, NULL);
SELECT * FROM mat_smallint ORDER BY 1;
 a | countb 
---+--------
(0 rows)

-- Case 1: overflow by subtracting from PG_INT16_MIN
--overflow start_interval, end_interval [-32768, -32768)
SELECT remove_continuous_aggregate_policy('mat_smallint');
 remove_continuous_aggregate_policy 
------------------------------------
 
(1 row)

INSERT INTO smallint_tab VALUES( -32768 );
SELECT integer_now_smallint_tab();
 integer_now_smallint_tab 
--------------------------
                   -32768
(1 row)

SELECT add_continuous_aggregate_policy('mat_smallint', 10::smallint, 5::smallint , '1 h'::interval) as job_id \gset
\set ON_ERROR_STOP 0
CALL run_job(:job_id);
ERROR:  invalid refresh window
\set ON_ERROR_STOP 1
SELECT * FROM mat_smallint ORDER BY 1;
 a | countb 
---+--------
(0 rows)

-- overflow start_interval. now this runs as range is capped [-32768, -32765)
INSERT INTO smallint_tab VALUES( -32760 );
SELECT maxval, maxval - 10, maxval -5 FROM integer_now_smallint_tab() as maxval;
 maxval | ?column? | ?column? 
--------+----------+----------
 -32760 |   -32770 |   -32765
(1 row)

CALL run_job(:job_id);
SELECT * FROM mat_smallint ORDER BY 1;
   a    | countb 
--------+--------
 -32768 |      1
(1 row)

--remove all the data--
TRUNCATE table smallint_tab;
CALL refresh_continuous_aggregate('mat_smallint', NULL, NULL);
SELECT * FROM mat_smallint ORDER BY 1;
 a | countb 
---+--------
(0 rows)

-- Case 2: overflow by subtracting from PG_INT16_MAX
--overflow start and end . will fail as range is [32767, 32767]
SELECT remove_continuous_aggregate_policy('mat_smallint');
 remove_continuous_aggregate_policy 
------------------------------------
 
(1 row)

INSERT INTO smallint_tab VALUES( 32766 );
INSERT INTO smallint_tab VALUES( 32767 );
SELECT maxval, maxval - (-1), maxval - (-2) FROM integer_now_smallint_tab() as maxval;
 maxval | ?column? | ?column? 
--------+----------+----------
  32767 |    32768 |    32769
(1 row)

SELECT add_continuous_aggregate_policy('mat_smallint', -1::smallint, -3::smallint , '1 h'::interval) as job_id \gset
\set ON_ERROR_STOP 0
CALL run_job(:job_id);
ERROR:  invalid refresh window
\set ON_ERROR_STOP 1
SELECT * FROM mat_smallint ORDER BY 1;
 a | countb 
---+--------
(0 rows)

SELECT remove_continuous_aggregate_policy('mat_smallint');
 remove_continuous_aggregate_policy 
------------------------------------
 
(1 row)

--overflow end . will work range is [32765, 32767)
SELECT maxval, maxval - (1), maxval - (-2) FROM integer_now_smallint_tab() as maxval;
 maxval | ?column? | ?column? 
--------+----------+----------
  32767 |    32766 |    32769
(1 row)

SELECT add_continuous_aggregate_policy('mat_smallint', 1::smallint, -3::smallint , '1 h'::interval) as job_id \gset
\set ON_ERROR_STOP 0
CALL run_job(:job_id);
SELECT * FROM mat_smallint ORDER BY 1;
   a   | countb 
-------+--------
 32766 |      1
(1 row)

-- tests for interval argument conversions
--
\set ON_ERROR_STOP 0
SELECT add_continuous_aggregate_policy('mat_smallint', 15, 10, '1h'::interval, if_not_exists=>true);
ERROR:  invalid parameter value for start_offset
SELECT add_continuous_aggregate_policy('mat_smallint', '15', 10, '1h'::interval, if_not_exists=>true);
ERROR:  invalid parameter value for end_offset
SELECT add_continuous_aggregate_policy('mat_smallint', '15', '10', '1h'::interval, if_not_exists=>true);
WARNING:  continuous aggregate policy already exists for "mat_smallint"
 add_continuous_aggregate_policy 
---------------------------------
                              -1
(1 row)

\set ON_ERROR_STOP 1
--bigint table
CREATE TABLE bigint_tab (a bigint);
SELECT table_name FROM create_hypertable('bigint_tab', 'a', chunk_time_interval=> 10);
NOTICE:  adding not-null constraint to column "a"
 table_name 
------------
 bigint_tab
(1 row)

CREATE OR REPLACE FUNCTION integer_now_bigint_tab() returns bigint LANGUAGE SQL STABLE as $$ SELECT 20::bigint $$;
SELECT set_integer_now_func('bigint_tab', 'integer_now_bigint_tab');
 set_integer_now_func 
----------------------
 
(1 row)

CREATE MATERIALIZED VIEW mat_bigint( a, countb )
WITH (timescaledb.continuous, timescaledb.materialized_only=true)
as
SELECT time_bucket( BIGINT '1', a) , count(*)
FROM bigint_tab
GROUP BY 1 WITH NO DATA;
\set ON_ERROR_STOP 0
SELECT add_continuous_aggregate_policy('mat_bigint', 5::bigint, 10::bigint , '1 h'::interval) ;
ERROR:  policy refresh window too small
\set ON_ERROR_STOP 1
SELECT add_continuous_aggregate_policy('mat_bigint', 15::bigint, 0::bigint , '1 h'::interval) as job_mid \gset
INSERT INTO bigint_tab VALUES(5);
INSERT INTO bigint_tab VALUES(10);
INSERT INTO bigint_tab VALUES(20);
CALL run_job(:job_mid);
SELECT * FROM mat_bigint;
 a  | countb 
----+--------
  5 |      1
 10 |      1
(2 rows)

-- test NULL for end
SELECT remove_continuous_aggregate_policy('mat_bigint');
 remove_continuous_aggregate_policy 
------------------------------------
 
(1 row)

SELECT add_continuous_aggregate_policy('mat_bigint', 1::smallint, NULL , '1 h'::interval) as job_id \gset
INSERT INTO bigint_tab VALUES(500);
CALL run_job(:job_id);
SELECT * FROM mat_bigint WHERE a>100 ORDER BY 1;
  a  | countb 
-----+--------
 500 |      1
(1 row)

ALTER MATERIALIZED VIEW mat_bigint SET (timescaledb.compress);
ALTER MATERIALIZED VIEW mat_smallint SET (timescaledb.compress);
\set ON_ERROR_STOP 0
SELECT add_compression_policy('mat_smallint', 0::smallint); 
ERROR:  compress_after value for compression policy should be greater than the start of the refresh window of continuous aggregate policy for mat_smallint
SELECT add_compression_policy('mat_smallint', -4::smallint); 
ERROR:  compress_after value for compression policy should be greater than the start of the refresh window of continuous aggregate policy for mat_smallint
SELECT add_compression_policy('mat_bigint', 0::bigint); 
ERROR:  compress_after value for compression policy should be greater than the start of the refresh window of continuous aggregate policy for mat_bigint
\set ON_ERROR_STOP 1
SELECT add_compression_policy('mat_smallint', 5::smallint); 
 add_compression_policy 
------------------------
                   1012
(1 row)

SELECT add_compression_policy('mat_bigint', 20::bigint); 
 add_compression_policy 
------------------------
                   1013
(1 row)

-- end of coverage tests
--TEST continuous aggregate + compression policy on caggs
CREATE TABLE metrics (
    time timestamptz NOT NULL,
    device_id int,
    device_id_peer int,
    v0 int,
    v1 int,
    v2 float,
    v3 float
);
SELECT create_hypertable('metrics', 'time');
   create_hypertable   
-----------------------
 (13,public,metrics,t)
(1 row)

INSERT INTO metrics (time, device_id, device_id_peer, v0, v1, v2, v3)
SELECT time,
    device_id,
    0,
    device_id + 1,
    device_id + 2,
    0.5,
    NULL
FROM generate_series('2000-01-01 0:00:00+0'::timestamptz, '2000-01-02 23:55:00+0', '20m') gtime (time), 
    generate_series(1, 2, 1) gdevice (device_id);
ALTER TABLE metrics SET ( timescaledb.compress );
SELECT compress_chunk(ch) FROM show_chunks('metrics') ch;
              compress_chunk              
------------------------------------------
 _timescaledb_internal._hyper_13_19_chunk
(1 row)

CREATE MATERIALIZED VIEW metrics_cagg WITH (timescaledb.continuous,
  timescaledb.materialized_only = true)
AS
SELECT time_bucket('1 day', time) as dayb, device_id,
       sum(v0), avg(v3)
FROM metrics
GROUP BY 1, 2
WITH NO DATA;
ALTER MATERIALIZED VIEW metrics_cagg SET (timescaledb.compress);
--can set compression policy only after setting up refresh policy --
\set ON_ERROR_STOP 0
SELECT add_compression_policy('metrics_cagg', '1 day'::interval);
ERROR:  setup a refresh policy for "metrics_cagg" before setting up a compression policy
\set ON_ERROR_STOP 1
SELECT add_continuous_aggregate_policy('metrics_cagg', '7 day'::interval, '1 day'::interval, '1 h'::interval) as "REFRESH_JOB" \gset
SELECT add_compression_policy('metrics_cagg', '8 day'::interval) AS "COMP_JOB" \gset 
--verify that jobs were added for the policies ---
SELECT materialization_hypertable_schema AS "MAT_SCHEMA_NAME",
       materialization_hypertable_name AS "MAT_TABLE_NAME",
       materialization_hypertable_schema || '.' || materialization_hypertable_name AS "MAT_NAME"
FROM timescaledb_information.continuous_aggregates
WHERE view_name = 'metrics_cagg' \gset
SELECT count(*) FROM timescaledb_information.jobs
WHERE hypertable_name = :'MAT_TABLE_NAME';
 count 
-------
     2
(1 row)

--exec the cagg compression job --
CALL refresh_continuous_aggregate('metrics_cagg', NULL, '2001-02-01 00:00:00+0');
CALL run_job(:COMP_JOB);
SELECT count(*), count(*) FILTER ( WHERE is_compressed is TRUE  )
FROM timescaledb_information.chunks
WHERE hypertable_name = :'MAT_TABLE_NAME' ORDER BY 1;
 count | count 
-------+-------
     1 |     1
(1 row)

--add some new data into metrics_cagg so that cagg policy job has something to do
INSERT INTO metrics (time, device_id, device_id_peer, v0, v1, v2, v3)
SELECT now() - '5 day'::interval, 102, 0, 10, 10, 10, 10;
CALL run_job(:REFRESH_JOB);
--now we have a new chunk and it is not compressed
SELECT count(*), count(*) FILTER ( WHERE is_compressed is TRUE  )
FROM timescaledb_information.chunks
WHERE hypertable_name = :'MAT_TABLE_NAME' ORDER BY 1;
 count | count 
-------+-------
     2 |     1
(1 row)

--verify that both jobs are dropped when view is dropped
DROP MATERIALIZED VIEW metrics_cagg;
NOTICE:  drop cascades to 2 other objects
SELECT count(*) FROM timescaledb_information.jobs
WHERE hypertable_name = :'MAT_TABLE_NAME';
 count 
-------
     0
(1 row)

